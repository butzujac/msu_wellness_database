{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a222f1",
   "metadata": {},
   "source": [
    "Before running the demo, download the spacy english model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397975f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a766c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhanced web scraping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_231564/2216989965.py:209: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_grouped[\"Total Mentions\"] = df[keywords].applymap(lambda x: x.count(\"Occurrence\") if isinstance(x, str) else 0).groupby(df[\"school_name\"]).sum().sum(axis=1).values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>Food Security</th>\n",
       "      <th>Housing Stability</th>\n",
       "      <th>Financial Assistance</th>\n",
       "      <th>Healthcare Services</th>\n",
       "      <th>Mental Health Support</th>\n",
       "      <th>Transportation Access</th>\n",
       "      <th>Personal Care Items</th>\n",
       "      <th>Childcare Support</th>\n",
       "      <th>Technology Access</th>\n",
       "      <th>...</th>\n",
       "      <th>Career Resources</th>\n",
       "      <th>Substance Abuse Support</th>\n",
       "      <th>Financial Counseling</th>\n",
       "      <th>Emergency Housing</th>\n",
       "      <th>Immigration &amp; International Student Support</th>\n",
       "      <th>Communication Services</th>\n",
       "      <th>Domestic Violence Resources</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phone Numbers</th>\n",
       "      <th>Total Mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNC</td>\n",
       "      <td>Occurrence 1: Our Staff Meet With DOS Events U...</td>\n",
       "      <td>No</td>\n",
       "      <td>Occurrence 1: To find out if your department c...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Occurrence 1: The goal is to provide resources...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Centercvrc@unc.edu, dos@unc.edu\\n\\nCentercvrc@...</td>\n",
       "      <td>919-966-4042, 919-962-9640\\n\\n919-966-4042, 91...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_name                                      Food Security  \\\n",
       "0         UNC  Occurrence 1: Our Staff Meet With DOS Events U...   \n",
       "\n",
       "  Housing Stability                               Financial Assistance  \\\n",
       "0                No  Occurrence 1: To find out if your department c...   \n",
       "\n",
       "  Healthcare Services Mental Health Support Transportation Access  \\\n",
       "0                  No                    No                    No   \n",
       "\n",
       "  Personal Care Items Childcare Support Technology Access  ...  \\\n",
       "0                  No                No                No  ...   \n",
       "\n",
       "  Career Resources Substance Abuse Support Financial Counseling  \\\n",
       "0               No                      No                   No   \n",
       "\n",
       "                                   Emergency Housing  \\\n",
       "0  Occurrence 1: The goal is to provide resources...   \n",
       "\n",
       "  Immigration & International Student Support Communication Services  \\\n",
       "0                                          No                     No   \n",
       "\n",
       "  Domestic Violence Resources  \\\n",
       "0                          No   \n",
       "\n",
       "                                              Emails  \\\n",
       "0  Centercvrc@unc.edu, dos@unc.edu\\n\\nCentercvrc@...   \n",
       "\n",
       "                                       Phone Numbers Total Mentions  \n",
       "0  919-966-4042, 919-962-9640\\n\\n919-966-4042, 91...             29  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "\n",
    "\n",
    "def generate_url_list(school_info, max_links=20):\n",
    "    \"\"\"\n",
    "    This function returns the subdomain links visible from a food bank or wellness programs homepage.\n",
    "    Params:\n",
    "        school_info: DataFrame with 'school_name' and 'url' columns\n",
    "        max_links: max size of the list being returned for each school\n",
    "    Returns:\n",
    "        result_df: DataFrame with 'school_name' and 'url' columns\n",
    "    \"\"\"\n",
    "    all_links = []  \n",
    "\n",
    "    \n",
    "    for index, row in school_info.iterrows():\n",
    "        #get school name and url to base/starting page\n",
    "        school_name = row[\"school_name\"] \n",
    "        url = row[\"url\"]  \n",
    "\n",
    "        \n",
    "        driver = webdriver.Chrome() \n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # parsing url to ensure consistency and proper formatting\n",
    "        parsed_url = urlparse(url)\n",
    "        #takes elements such as scheme and netloc to create valid base domain\n",
    "        base_domain = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
    "\n",
    "        # set data structure used to avoid duplicates\n",
    "        links = set()\n",
    "\n",
    "        #looping though each sublink\n",
    "        for a in driver.find_elements(By.TAG_NAME, \"a\"):\n",
    "            href = a.get_attribute(\"href\")\n",
    "            if href: # if link exists\n",
    "                # joining to ensure only focused websites are being generated\n",
    "                full_link = urljoin(base_domain, href)\n",
    "                #adding to list of links if it has base domain \n",
    "                if full_link.startswith(base_domain) and full_link not in links:\n",
    "                    links.add(full_link)\n",
    "                    if len(links) >= max_links: #stopping point after max_links\n",
    "                        break\n",
    "\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        # all links for a school will have school name but different urls\n",
    "        for link in links:\n",
    "            all_links.append({\"school_name\": school_name, \"url\": link})\n",
    "\n",
    "    # conver to dataframe \n",
    "    result_df = pd.DataFrame(all_links)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "# small example of dataframe for 5 schools\n",
    "school_info = pd.read_csv(\"docs/university_food_pantries_list.csv\")[0:5]\n",
    "\n",
    "\n",
    "result = generate_url_list(school_info)\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Urls and school names list \n",
    "university_urls = result[\"url\"]\n",
    "school_names = result[\"school_name\"]\n",
    "\n",
    "\n",
    "keywords = [\n",
    "    \"Food Security\", \"Housing Stability\", \"Financial Assistance\", \"Healthcare Services\", \"Mental Health Support\",\n",
    "    \"Transportation Access\", \"Personal Care Items\", \"Childcare Support\", \"Technology Access\", \"Clothing & Weather Essentials\",\n",
    "    \"Academic Support\", \"Community & Belonging\", \"School Supplies\", \"Cooking Supplies\", \"Cleaning Supplies\",\n",
    "    \"Nutrition Education\", \"Financial Literacy\", \"Legal Support\", \"Crisis Intervention\", \"Laundry Access\",\n",
    "    \"Career Resources\", \"Substance Abuse Support\", \"Financial Counseling\", \"Emergency Housing\", \n",
    "    \"Immigration & International Student Support\", \"Communication Services\", \"Domestic Violence Resources\"\n",
    "]\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "data = []\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Removes excessive spaces, newlines, and special characters from text.\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "#updated extraction function\n",
    "def extract_relevant_text(url, limit = 10):\n",
    "    \"\"\"Extracts relevant content and retrieves keyword occurrences with sentence context.\"\"\"\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    text = clean_text(soup.get_text())\n",
    "    extracted_info = {\"URL\": url, \"Text\": text}\n",
    "\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Tokenize into sentences\n",
    "    total_occurrences = []\n",
    "    #loop through the keyword list\n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.lower()\n",
    "        occurrences = []\n",
    "        \n",
    "        # Find occurences\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if keyword_lower in sentence.lower():  # If the keyword is found in the sentence\n",
    "                before = sentences[i - 1] if i > 0 else \" \"  # Previous sentence\n",
    "                after = sentences[i + 1] if i < len(sentences) - 1 else \"N/A\"  # Next sentence\n",
    "                highlighted_sentence = sentence.replace(keyword, keyword.upper())\n",
    "                occurrence_text = f\"Occurrence X: {before} {highlighted_sentence} {after} \\n\"\n",
    "                occurrences.append(occurrence_text)\n",
    "                total_occurrences.append(occurrence_text)\n",
    "            if len(total_occurrences) >= 5:\n",
    "                break\n",
    "        # Placing the occurences into the same column separated by ||\n",
    "        extracted_info[keyword] = \"\\n\".join(occurrences) + \"\\n\" + url if occurrences else \"No\"\n",
    "        if len(total_occurrences) >= 5:\n",
    "            break\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "\n",
    "def extract_contact_info(text):\n",
    "    \"\"\"Extracts email and phone numbers from the scraped text.\"\"\"\n",
    "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "    phones = re.findall(r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}', text)\n",
    "    return {\"Emails\": \", \".join(set(emails)), \"Phone Numbers\": \", \".join(set(phones))}\n",
    "\n",
    "\n",
    "print(\"Starting enhanced web scraping...\")\n",
    "for url in university_urls:\n",
    "    try:\n",
    "        #print(f\"Scraping: {url}\")\n",
    "        extracted_data = extract_relevant_text(url)\n",
    "        contact_info = extract_contact_info(extracted_data[\"Text\"])\n",
    "#         categorized_data = categorize_services(extracted_data[\"Text\"])\n",
    "        \n",
    "        # Merge all extracted data and got rid of the categorized data\n",
    "        final_data = {**extracted_data, **contact_info}  #, **categorized_data\n",
    "        data.append(final_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(columns=[\"Text\"], inplace=True) \n",
    "df[\"school_name\"] = result[\"school_name\"] # Remove raw text to keep CSV clean\n",
    "\n",
    "#df\n",
    "\n",
    "\n",
    "#Aggregate keyword occurrences into a single row per school\n",
    "def merge_occurrences(series):\n",
    "    \"\"\"Merge occurrences from multiple sublinks, ensuring proper sequencing.\"\"\"\n",
    "    unique_values = series.dropna().unique()\n",
    "    filtered_values = [val for val in unique_values if val != \"No\"]\n",
    "\n",
    "    if not filtered_values:\n",
    "        return \"No\"\n",
    "\n",
    "    # Step 1: Standardize occurrence format (replace numbers with 'X')\n",
    "    occurrences = \"\\n\".join(filtered_values)\n",
    "    occurrence_list = [line for line in occurrences.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    # Step 3: Renumber properly\n",
    "    reordered = []\n",
    "    for i, occ in enumerate(occurrence_list):\n",
    "        reordered.append(occ.replace(\"Occurrence X:\", f\"Occurrence {i + 1}:\") + \"\\n\")\n",
    "\n",
    "    return \"\\n\".join(reordered)\n",
    "\n",
    "\n",
    "#Count total mentions per school\n",
    "def count_mentions(series):\n",
    "    \"\"\"Count total keyword mentions across multiple rows for a school.\"\"\"\n",
    "    return series.str.count(\"Occurrence\").sum()\n",
    "\n",
    "#Perform groupby aggregation\n",
    "agg_dict = {keyword: merge_occurrences for keyword in keywords}\n",
    "agg_dict[\"Emails\"] = merge_occurrences\n",
    "agg_dict[\"Phone Numbers\"] = merge_occurrences\n",
    "\n",
    "df_grouped = df.groupby(\"school_name\").agg(agg_dict).reset_index()\n",
    "\n",
    "#Create a new column for total keyword mentions\n",
    "df_grouped[\"Total Mentions\"] = df[keywords].applymap(lambda x: x.count(\"Occurrence\") if isinstance(x, str) else 0).groupby(df[\"school_name\"]).sum().sum(axis=1).values\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0ee61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"first_word_search.csv\", index=False)\n",
    "df_grouped.to_csv(\"/home/jack/MSU/CMSE495/condensed_word_search_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05cbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
